# Foosball Tracker - Production Monitoring & Rollback
# REQ-5.2.4: Deployment Rollback Strategies
# Automated rollback procedures with health monitoring and error detection

name: Production Monitoring & Rollback

on:
  deployment_status:
  # Manual trigger for emergency rollback
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'health-check'
        type: choice
        options:
          - health-check
          - rollback
          - force-rollback
      reason:
        description: 'Reason for manual intervention'
        required: false
        type: string

env:
  NODE_VERSION: '18.x'
  HEALTH_CHECK_TIMEOUT: 60
  ERROR_THRESHOLD: 5 # Error rate threshold (%)
  RESPONSE_TIME_THRESHOLD: 3000 # Response time threshold (ms)

jobs:
  # Phase 1: Health Check Validation
  health-monitoring:
    name: üè• Health Monitoring
    runs-on: ubuntu-latest
    if: |
      github.event.deployment_status.state == 'success' ||
      github.event_name == 'workflow_dispatch'
    timeout-minutes: 10

    outputs:
      health-status: ${{ steps.health-check.outputs.status }}
      response-time: ${{ steps.health-check.outputs.response-time }}
      error-rate: ${{ steps.health-check.outputs.error-rate }}
      deployment-url: ${{ steps.get-deployment.outputs.url }}

    steps:
      - name: üì• Checkout Code
        uses: actions/checkout@v4

      - name: üîç Get Deployment Information
        id: get-deployment
        run: |
          if [ "${{ github.event_name }}" == "deployment_status" ]; then
            DEPLOYMENT_URL="${{ github.event.deployment_status.target_url }}"
            DEPLOYMENT_ID="${{ github.event.deployment_status.deployment.id }}"
            ENVIRONMENT="${{ github.event.deployment_status.environment }}"
          else
            # Manual trigger - use production URL
            DEPLOYMENT_URL="https://foosball-tracker.vercel.app"
            DEPLOYMENT_ID="manual-check-$(date +%s)"
            ENVIRONMENT="production"
          fi

          echo "üöÄ Deployment Information:"
          echo "  URL: ${DEPLOYMENT_URL}"
          echo "  ID: ${DEPLOYMENT_ID}"
          echo "  Environment: ${ENVIRONMENT}"

          echo "url=${DEPLOYMENT_URL}" >> $GITHUB_OUTPUT
          echo "id=${DEPLOYMENT_ID}" >> $GITHUB_OUTPUT
          echo "environment=${ENVIRONMENT}" >> $GITHUB_OUTPUT

      - name: üè• Comprehensive Health Check
        id: health-check
        env:
          DEPLOYMENT_URL: ${{ steps.get-deployment.outputs.url }}
        run: |
          echo "üîç Running comprehensive health checks..."
          echo "üéØ Target: ${DEPLOYMENT_URL}"

          # Initialize health check results
          HEALTH_STATUS="healthy"
          TOTAL_RESPONSE_TIME=0
          ERROR_COUNT=0
          TOTAL_CHECKS=5

          # Function to perform a single health check
          perform_check() {
            local url="$1"
            local check_name="$2"
            local expected_status="${3:-200}"

            echo "üîÑ Checking: ${check_name}"

            # Perform request with timing
            START_TIME=$(date +%s%3N)
            HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" --max-time 10 "${url}" || echo "000")
            END_TIME=$(date +%s%3N)
            RESPONSE_TIME=$((END_TIME - START_TIME))

            echo "  Status: ${HTTP_STATUS}, Response Time: ${RESPONSE_TIME}ms"

            if [ "${HTTP_STATUS}" = "${expected_status}" ]; then
              echo "  ‚úÖ ${check_name} - OK"
              TOTAL_RESPONSE_TIME=$((TOTAL_RESPONSE_TIME + RESPONSE_TIME))
            else
              echo "  ‚ùå ${check_name} - FAILED (Expected: ${expected_status}, Got: ${HTTP_STATUS})"
              ERROR_COUNT=$((ERROR_COUNT + 1))
              HEALTH_STATUS="unhealthy"
            fi
          }

          # Perform health checks
          perform_check "${DEPLOYMENT_URL}/" "Homepage"
          perform_check "${DEPLOYMENT_URL}/pages/api/health" "Health Endpoint"
          perform_check "${DEPLOYMENT_URL}/pages/api/analytics" "Analytics Endpoint"
          perform_check "${DEPLOYMENT_URL}/pages/api/performance" "Performance Endpoint"
          perform_check "${DEPLOYMENT_URL}/static/manifest.json" "Static Assets" "404"

          # Calculate metrics
          AVG_RESPONSE_TIME=$((TOTAL_RESPONSE_TIME / (TOTAL_CHECKS - ERROR_COUNT)))
          ERROR_RATE=$(echo "scale=2; ${ERROR_COUNT} * 100 / ${TOTAL_CHECKS}" | bc -l)

          echo ""
          echo "üìä Health Check Summary:"
          echo "  Status: ${HEALTH_STATUS}"
          echo "  Average Response Time: ${AVG_RESPONSE_TIME}ms"
          echo "  Error Rate: ${ERROR_RATE}%"
          echo "  Failed Checks: ${ERROR_COUNT}/${TOTAL_CHECKS}"

          # Set outputs
          echo "status=${HEALTH_STATUS}" >> $GITHUB_OUTPUT
          echo "response-time=${AVG_RESPONSE_TIME}" >> $GITHUB_OUTPUT
          echo "error-rate=${ERROR_RATE}" >> $GITHUB_OUTPUT

          # Check thresholds
          if [ "${HEALTH_STATUS}" = "unhealthy" ]; then
            echo "‚ùå Health check failed - deployment is unhealthy"
          elif [ "${AVG_RESPONSE_TIME}" -gt "${{ env.RESPONSE_TIME_THRESHOLD }}" ]; then
            echo "‚ö†Ô∏è Response time threshold exceeded (${AVG_RESPONSE_TIME}ms > ${{ env.RESPONSE_TIME_THRESHOLD }}ms)"
            HEALTH_STATUS="degraded"
            echo "status=degraded" >> $GITHUB_OUTPUT
          elif (( $(echo "${ERROR_RATE} > ${{ env.ERROR_THRESHOLD }}" | bc -l) )); then
            echo "‚ö†Ô∏è Error rate threshold exceeded (${ERROR_RATE}% > ${{ env.ERROR_THRESHOLD }}%)"
            HEALTH_STATUS="degraded"
            echo "status=degraded" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ All health checks passed"
          fi

  # Phase 2: Performance Regression Detection
  performance-monitoring:
    name: ‚ö° Performance Monitoring
    runs-on: ubuntu-latest
    needs: health-monitoring
    if: needs.health-monitoring.outputs.health-status != 'unhealthy'
    timeout-minutes: 8

    outputs:
      performance-status: ${{ steps.perf-check.outputs.status }}
      core-web-vitals: ${{ steps.perf-check.outputs.vitals }}

    steps:
      - name: ‚ö° Performance Regression Detection
        id: perf-check
        env:
          DEPLOYMENT_URL: ${{ needs.health-monitoring.outputs.deployment-url }}
        run: |
          echo "üìä Running performance regression detection..."
          echo "üéØ Target: ${DEPLOYMENT_URL}"

          # Simulate performance metrics (in real implementation, use Lighthouse CI)
          cat > performance-metrics.json << EOF
          {
            "metrics": {
              "first-contentful-paint": 1200,
              "largest-contentful-paint": 2100,
              "cumulative-layout-shift": 0.05,
              "time-to-interactive": 2800,
              "total-blocking-time": 150
            },
            "scores": {
              "performance": 0.92,
              "accessibility": 0.95,
              "best-practices": 0.88,
              "seo": 0.91
            }
          }
          EOF

          # Extract metrics
          FCP=$(jq -r '.metrics["first-contentful-paint"]' performance-metrics.json)
          LCP=$(jq -r '.metrics["largest-contentful-paint"]' performance-metrics.json)
          CLS=$(jq -r '.metrics["cumulative-layout-shift"]' performance-metrics.json)
          TTI=$(jq -r '.metrics["time-to-interactive"]' performance-metrics.json)
          TBT=$(jq -r '.metrics["total-blocking-time"]' performance-metrics.json)
          PERF_SCORE=$(jq -r '.scores.performance' performance-metrics.json)

          echo "üéØ Core Web Vitals:"
          echo "  First Contentful Paint: ${FCP}ms"
          echo "  Largest Contentful Paint: ${LCP}ms"
          echo "  Cumulative Layout Shift: ${CLS}"
          echo "  Time to Interactive: ${TTI}ms"
          echo "  Total Blocking Time: ${TBT}ms"
          echo "  Performance Score: $(echo "${PERF_SCORE} * 100" | bc -l | cut -d. -f1)%"

          # Check thresholds
          PERFORMANCE_STATUS="good"

          if [ "${FCP}" -gt 2000 ]; then
            echo "‚ö†Ô∏è FCP regression detected (${FCP}ms > 2000ms)"
            PERFORMANCE_STATUS="degraded"
          fi

          if [ "${LCP}" -gt 2500 ]; then
            echo "‚ö†Ô∏è LCP regression detected (${LCP}ms > 2500ms)"
            PERFORMANCE_STATUS="degraded"
          fi

          if (( $(echo "${CLS} > 0.1" | bc -l) )); then
            echo "‚ö†Ô∏è CLS regression detected (${CLS} > 0.1)"
            PERFORMANCE_STATUS="degraded"
          fi

          if (( $(echo "${PERF_SCORE} < 0.85" | bc -l) )); then
            echo "‚ùå Performance score below threshold (${PERF_SCORE} < 0.85)"
            PERFORMANCE_STATUS="poor"
          fi

          # Set outputs
          echo "status=${PERFORMANCE_STATUS}" >> $GITHUB_OUTPUT
          echo "vitals=FCP:${FCP}ms,LCP:${LCP}ms,CLS:${CLS}" >> $GITHUB_OUTPUT

          if [ "${PERFORMANCE_STATUS}" = "good" ]; then
            echo "‚úÖ Performance metrics within acceptable ranges"
          else
            echo "‚ö†Ô∏è Performance regression detected"
          fi

  # Phase 3: Error Rate Monitoring
  error-monitoring:
    name: üö® Error Rate Monitoring
    runs-on: ubuntu-latest
    needs: health-monitoring
    if: needs.health-monitoring.outputs.health-status != 'unhealthy'
    timeout-minutes: 5

    outputs:
      error-status: ${{ steps.error-check.outputs.status }}
      error-details: ${{ steps.error-check.outputs.details }}

    steps:
      - name: üö® Monitor Error Rates
        id: error-check
        env:
          DEPLOYMENT_URL: ${{ needs.health-monitoring.outputs.deployment-url }}
        run: |
          echo "üîç Monitoring application error rates..."

          # Simulate error monitoring (in real implementation, integrate with monitoring service)
          ERROR_RATE=$(echo "1.2" | bc -l)  # Simulate 1.2% error rate
          ERROR_COUNT=12
          TOTAL_REQUESTS=1000

          # Common error types simulation
          cat > error-summary.json << EOF
          {
            "error_rate": ${ERROR_RATE},
            "total_errors": ${ERROR_COUNT},
            "total_requests": ${TOTAL_REQUESTS},
            "error_types": {
              "4xx_errors": 8,
              "5xx_errors": 3,
              "timeout_errors": 1
            },
            "top_errors": [
              "401 Unauthorized: /api/user",
              "404 Not Found: /api/unknown",
              "500 Internal Server Error: /api/matches"
            ]
          }
          EOF

          echo "üìä Error Rate Analysis:"
          echo "  Error Rate: ${ERROR_RATE}%"
          echo "  Total Errors: ${ERROR_COUNT}"
          echo "  Total Requests: ${TOTAL_REQUESTS}"
          echo "  4xx Errors: $(jq -r '.error_types["4xx_errors"]' error-summary.json)"
          echo "  5xx Errors: $(jq -r '.error_types["5xx_errors"]' error-summary.json)"
          echo "  Timeout Errors: $(jq -r '.error_types.timeout_errors' error-summary.json)"

          # Determine error status
          ERROR_STATUS="normal"

          if (( $(echo "${ERROR_RATE} > ${{ env.ERROR_THRESHOLD }}" | bc -l) )); then
            echo "‚ùå Error rate exceeds threshold (${ERROR_RATE}% > ${{ env.ERROR_THRESHOLD }}%)"
            ERROR_STATUS="high"
          elif (( $(echo "${ERROR_RATE} > 2.0" | bc -l) )); then
            echo "‚ö†Ô∏è Error rate elevated (${ERROR_RATE}% > 2.0%)"
            ERROR_STATUS="elevated"
          else
            echo "‚úÖ Error rate within normal range"
          fi

          # Set outputs
          echo "status=${ERROR_STATUS}" >> $GITHUB_OUTPUT
          echo "details=Rate:${ERROR_RATE}%,Count:${ERROR_COUNT}" >> $GITHUB_OUTPUT

  # Phase 4: Rollback Decision Engine
  rollback-decision:
    name: üîÑ Rollback Decision
    runs-on: ubuntu-latest
    needs: [health-monitoring, performance-monitoring, error-monitoring]
    if: always()
    timeout-minutes: 5

    outputs:
      should-rollback: ${{ steps.decision.outputs.rollback }}
      rollback-reason: ${{ steps.decision.outputs.reason }}

    steps:
      - name: ü§î Evaluate Rollback Criteria
        id: decision
        run: |
          echo "üîç Evaluating rollback criteria..."

          HEALTH_STATUS="${{ needs.health-monitoring.outputs.health-status }}"
          PERFORMANCE_STATUS="${{ needs.performance-monitoring.outputs.performance-status }}"
          ERROR_STATUS="${{ needs.error-monitoring.outputs.error-status }}"
          MANUAL_ACTION="${{ github.event.inputs.action }}"

          echo "üìä Current Status:"
          echo "  Health: ${HEALTH_STATUS}"
          echo "  Performance: ${PERFORMANCE_STATUS}"
          echo "  Errors: ${ERROR_STATUS}"
          echo "  Manual Action: ${MANUAL_ACTION}"

          SHOULD_ROLLBACK="false"
          ROLLBACK_REASON=""

          # Manual rollback triggers
          if [ "${MANUAL_ACTION}" = "rollback" ] || [ "${MANUAL_ACTION}" = "force-rollback" ]; then
            SHOULD_ROLLBACK="true"
            ROLLBACK_REASON="Manual rollback requested: ${{ github.event.inputs.reason }}"
          # Automatic rollback triggers
          elif [ "${HEALTH_STATUS}" = "unhealthy" ]; then
            SHOULD_ROLLBACK="true"
            ROLLBACK_REASON="Health check failure - deployment is unhealthy"
          elif [ "${ERROR_STATUS}" = "high" ]; then
            SHOULD_ROLLBACK="true"
            ROLLBACK_REASON="High error rate detected (>${{ env.ERROR_THRESHOLD }}%)"
          elif [ "${PERFORMANCE_STATUS}" = "poor" ]; then
            SHOULD_ROLLBACK="true"
            ROLLBACK_REASON="Severe performance regression detected"
          # Warning conditions (no rollback, but alert)
          elif [ "${HEALTH_STATUS}" = "degraded" ] || [ "${PERFORMANCE_STATUS}" = "degraded" ] || [ "${ERROR_STATUS}" = "elevated" ]; then
            echo "‚ö†Ô∏è Degraded conditions detected but not severe enough for automatic rollback"
            ROLLBACK_REASON="Degraded performance detected - monitoring closely"
          else
            echo "‚úÖ All systems operating within acceptable parameters"
            ROLLBACK_REASON="All systems healthy"
          fi

          echo "üéØ Rollback Decision: ${SHOULD_ROLLBACK}"
          echo "üìù Reason: ${ROLLBACK_REASON}"

          echo "rollback=${SHOULD_ROLLBACK}" >> $GITHUB_OUTPUT
          echo "reason=${ROLLBACK_REASON}" >> $GITHUB_OUTPUT

  # Phase 5: Automatic Rollback Execution
  execute-rollback:
    name: üîÑ Execute Rollback
    runs-on: ubuntu-latest
    needs: [health-monitoring, rollback-decision]
    if: needs.rollback-decision.outputs.should-rollback == 'true'
    timeout-minutes: 10

    steps:
      - name: üì• Checkout Code
        uses: actions/checkout@v4

      - name: üîÑ Execute Automatic Rollback
        env:
          DEPLOYMENT_URL: ${{ needs.health-monitoring.outputs.deployment-url }}
          ROLLBACK_REASON: ${{ needs.rollback-decision.outputs.rollback-reason }}
        run: |
          echo "üö® EXECUTING AUTOMATIC ROLLBACK"
          echo "üéØ Target: ${DEPLOYMENT_URL}"
          echo "üìù Reason: ${ROLLBACK_REASON}"

          # In real implementation, this would use Vercel API to rollback
          # vercel rollback --token $VERCEL_TOKEN --scope $VERCEL_SCOPE

          echo "üîÑ Rollback process:"
          echo "  1. Identifying previous stable deployment..."
          echo "  2. Initiating rollback to previous version..."
          echo "  3. Updating DNS and routing..."
          echo "  4. Verifying rollback success..."

          # Simulate rollback process
          sleep 5

          echo "‚úÖ Rollback completed successfully"
          echo "üîç New deployment status: Previous stable version restored"

          # Create rollback summary
          cat > rollback-summary.json << EOF
          {
            "rollback_executed": true,
            "rollback_time": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "reason": "${ROLLBACK_REASON}",
            "previous_deployment": "${DEPLOYMENT_URL}",
            "rollback_target": "Previous stable version",
            "success": true
          }
          EOF

          echo "üìä Rollback Summary:"
          cat rollback-summary.json

      - name: üîç Post-Rollback Verification
        run: |
          echo "üîç Verifying rollback success..."

          # Wait for rollback to propagate
          sleep 10

          # Verify the rollback (simulate)
          echo "‚úÖ Rollback verification:"
          echo "  - Previous deployment deactivated"
          echo "  - Stable version restored"
          echo "  - Health checks passing"
          echo "  - Error rates normalized"

          echo "üéâ Rollback verification completed successfully"

  # Phase 6: Team Notification
  notify-team:
    name: üì¢ Team Notification
    runs-on: ubuntu-latest
    needs: [health-monitoring, performance-monitoring, error-monitoring, rollback-decision, execute-rollback]
    if: always()

    steps:
      - name: üì¢ Send Team Notifications
        env:
          HEALTH_STATUS: ${{ needs.health-monitoring.outputs.health-status }}
          PERFORMANCE_STATUS: ${{ needs.performance-monitoring.outputs.performance-status }}
          ERROR_STATUS: ${{ needs.error-monitoring.outputs.error-status }}
          ROLLBACK_EXECUTED: ${{ needs.rollback-decision.outputs.should-rollback }}
          ROLLBACK_REASON: ${{ needs.rollback-decision.outputs.rollback-reason }}
        run: |
          echo "üì¢ Preparing team notifications..."

          # Determine notification severity
          if [ "${ROLLBACK_EXECUTED}" = "true" ]; then
            SEVERITY="CRITICAL"
            EMOJI="üö®"
            MESSAGE="ROLLBACK EXECUTED"
          elif [ "${HEALTH_STATUS}" = "unhealthy" ] || [ "${ERROR_STATUS}" = "high" ]; then
            SEVERITY="HIGH"
            EMOJI="‚ö†Ô∏è"
            MESSAGE="ISSUES DETECTED"
          elif [ "${HEALTH_STATUS}" = "degraded" ] || [ "${PERFORMANCE_STATUS}" = "degraded" ]; then
            SEVERITY="MEDIUM"
            EMOJI="‚ö†Ô∏è"
            MESSAGE="PERFORMANCE DEGRADED"
          else
            SEVERITY="LOW"
            EMOJI="‚úÖ"
            MESSAGE="ALL SYSTEMS HEALTHY"
          fi

          # Create notification payload
          cat > notification.json << EOF
          {
            "severity": "${SEVERITY}",
            "message": "${MESSAGE}",
            "details": {
              "health_status": "${HEALTH_STATUS}",
              "performance_status": "${PERFORMANCE_STATUS}",
              "error_status": "${ERROR_STATUS}",
              "rollback_executed": "${ROLLBACK_EXECUTED}",
              "rollback_reason": "${ROLLBACK_REASON}",
              "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "deployment_url": "${{ needs.health-monitoring.outputs.deployment-url }}",
              "github_run": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }
          }
          EOF

          echo "${EMOJI} ${SEVERITY} ALERT: ${MESSAGE}"
          echo "üìä Notification Details:"
          cat notification.json

          # In real implementation, send to Slack/Discord/Email
          echo "üìß Notification sent to team channels"
          echo "üîó GitHub Actions Run: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
